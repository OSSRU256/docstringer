#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import argparse
import ast
import fnmatch
import logging
import os
import sys
import textwrap
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

from dotenv import load_dotenv

load_dotenv()

try:
    import tomllib
except ModuleNotFoundError:
    try:
        import toml as tomllib
    except ModuleNotFoundError:
        print("–û—à–∏–±–∫–∞: –ù–µ –Ω–∞–π–¥–µ–Ω—ã –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ 'tomllib' (Python 3.11+) –∏–ª–∏ 'toml'.")
        print("–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ 'toml': pip install toml")
        sys.exit(1)

try:
    import google.generativeai as genai
    from rich.console import Console
    from rich.panel import Panel
    from rich.progress import (
        BarColumn,
        Progress,
        SpinnerColumn,
        TextColumn,
        TimeElapsedColumn,
    )
    from rich.syntax import Syntax
except ModuleNotFoundError:
    print("–û—à–∏–±–∫–∞: –ù–µ –Ω–∞–π–¥–µ–Ω—ã –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ 'google-generativeai' –∏–ª–∏ 'rich'.")
    print("–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∏—Ö: pip install google-generativeai rich")
    sys.exit(1)

logging.basicConfig(level=logging.WARNING, format="%(levelname)s: %(message)s")
log = logging.getLogger(__name__)

CONFIG_SECTION = "tool.auto_docstringer"
DEFAULT_EXCLUDE_PATTERNS = ["*/migrations/*", "manage.py", "tests/*", "**/__init__.py"]
DEFAULT_GEMINI_MODEL = "gemini-1.5-flash"
API_KEY_ENV_VAR = "GEMINI_API_KEY"

console = Console()


def load_config(project_path: Path) -> Dict[str, Any]:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∏–∑ pyproject.toml."""
    config_file = project_path / "pyproject.toml"
    if not config_file.is_file():
        log.warning(f"–§–∞–π–ª –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ {config_file} –Ω–µ –Ω–∞–π–¥–µ–Ω.")
        return {}
    try:
        with open(config_file, "rb") as f:
            data = tomllib.load(f)

        config_parts = CONFIG_SECTION.split(".")
        current = data
        for part in config_parts:
            if part not in current:
                log.warning(
                    f"–°–µ–∫—Ü–∏—è '{part}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏. –ü–æ–ª–Ω—ã–π –ø—É—Ç—å: {CONFIG_SECTION}"
                )
                return {}
            current = current[part]

        log.debug(f"–ó–∞–≥—Ä—É–∂–µ–Ω–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è: {current}")
        return current
    except Exception as e:
        log.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è {config_file}: {e}")
        return {}


def find_python_files(project_path: Path, exclude_patterns: List[str]) -> List[Path]:
    """–ù–∞—Ö–æ–¥–∏—Ç –≤—Å–µ Python —Ñ–∞–π–ª—ã –≤ –ø—Ä–æ–µ–∫—Ç–µ, –∏—Å–∫–ª—é—á–∞—è —É–∫–∞–∑–∞–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∏ —Å–∞–º —Å–∫—Ä–∏–ø—Ç."""
    py_files = []
    project_root_str = str(project_path.resolve())
    try:
        script_path = Path(__file__).resolve()
    except NameError:
        script_path = None
        log.warning(
            "–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –ø—É—Ç—å –∫ –∑–∞–ø—É—â–µ–Ω–Ω–æ–º—É —Å–∫—Ä–∏–ø—Ç—É, —Å–∞–º–æ–∏—Å–∫–ª—é—á–µ–Ω–∏–µ –º–æ–∂–µ—Ç –Ω–µ —Å—Ä–∞–±–æ—Ç–∞—Ç—å."
        )

    processed_patterns = []
    for pattern in exclude_patterns:
        if pattern.endswith("/"):
            base_pattern = pattern.rstrip("/")
            processed_patterns.append(f"{base_pattern}/**")
            processed_patterns.append(base_pattern)
            processed_patterns.append(f"{base_pattern}*")
        else:
            processed_patterns.append(pattern)

    root_dirs_to_exclude = [
        pattern.rstrip("/")
        for pattern in exclude_patterns
        if pattern.endswith("/") and "/" not in pattern.rstrip("/")
    ]

    log.debug(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∏—Å–∫–ª—é—á–µ–Ω–∏—è (–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ): {processed_patterns}")

    for path in project_path.rglob("*.py"):
        log.debug(f"–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–∞–π–ª–∞: {path}")

        if script_path and path.resolve() == script_path:
            log.debug(f"–ò—Å–∫–ª—é—á–µ–Ω —Å–∞–º —Å–∫—Ä–∏–ø—Ç: {path.relative_to(project_path)}")
            continue

        relative_path = path.relative_to(project_path)
        normalized_path = relative_path.as_posix()

        log.debug(f"  –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π –ø—É—Ç—å: {normalized_path}")

        is_excluded = False

        for root_dir in root_dirs_to_exclude:
            if normalized_path.startswith(f"{root_dir}/"):
                log.debug(f"    -> –ò–°–ö–õ–Æ–ß–ï–ù–û (–∫–æ—Ä–Ω–µ–≤–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è '{root_dir}/')")
                is_excluded = True
                break

        if not is_excluded:
            for pattern in processed_patterns:
                log.debug(f"    –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–∞—Ç—Ç–µ—Ä–Ω–∞: '{pattern}'")

                if fnmatch.fnmatch(normalized_path, pattern):
                    is_excluded = True
                    log.debug(f"      -> –ò–°–ö–õ–Æ–ß–ï–ù–û (–ø–∞—Ç—Ç–µ—Ä–Ω '{pattern}')")
                    break

        if not is_excluded:
            log.debug(f"  -> –í–ö–õ–Æ–ß–ï–ù —Ñ–∞–π–ª: {normalized_path}")
            py_files.append(path)

    return py_files


class DocstringFinder(ast.NodeVisitor):
    """
    –û–±—Ö–æ–¥–∏—Ç AST –∏ –Ω–∞—Ö–æ–¥–∏—Ç —É–∑–ª—ã (–º–æ–¥—É–ª—å, –∫–ª–∞—Å—Å—ã, —Ñ—É–Ω–∫—Ü–∏–∏) –±–µ–∑ –¥–æ–∫—Å—Ç—Ä–∏–Ω–≥–æ–≤.
    """

    def __init__(self, file_path: Path):
        self.file_path = file_path
        self.nodes_without_docstrings: List[Tuple[ast.AST, str]] = []

    def _get_source_segment(self, node: ast.AST) -> Optional[str]:
        """–ü—ã—Ç–∞–µ—Ç—Å—è –ø–æ–ª—É—á–∏—Ç—å –∏—Å—Ö–æ–¥–Ω—ã–π –∫–æ–¥ –¥–ª—è —É–∑–ª–∞."""
        try:
            if sys.version_info >= (3, 8):
                try:
                    with open(self.file_path, "r", encoding="utf-8") as f:
                        source = f.read()
                    return ast.get_source_segment(source, node)
                except Exception:
                    log.warning(
                        f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–µ–≥–º–µ–Ω—Ç –∫–æ–¥–∞ –¥–ª—è —É–∑–ª–∞ –≤ {self.file_path}:{node.lineno}"
                    )
                    return None
            else:
                log.warning(
                    "ast.get_source_segment –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –≤ —ç—Ç–æ–π –≤–µ—Ä—Å–∏–∏ Python. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –º–æ–∂–µ—Ç –±—ã—Ç—å –º–µ–Ω–µ–µ —Ç–æ—á–Ω–æ–π."
                )
                return None
        except Exception as e:
            log_line_info = f":{node.lineno}" if hasattr(node, "lineno") else ":module"
            log.debug(
                f"–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–æ–∫—Å—Ç—Ä–∏–Ω–≥–∞ –¥–ª—è {node_type} '{name}' –≤ {relative_file_path}{log_line_info}"
            )
            return None

    def visit_Module(self, node: ast.Module):
        docstring = ast.get_docstring(node, clean=False)
        if not docstring:
            self.nodes_without_docstrings.append(
                (node, f"# Module: {self.file_path.name}")
            )
        self.generic_visit(node)

    def visit_FunctionDef(self, node: ast.FunctionDef):
        if not node.name.startswith("_") and not (
            node.name.startswith("get_")
            and len(node.body) == 1
            and isinstance(node.body[0], ast.Return)
        ):
            docstring = ast.get_docstring(node, clean=False)
            if not docstring:
                segment = self._get_source_segment(node)
                if segment:
                    self.nodes_without_docstrings.append((node, segment))
        self.generic_visit(node)

    def visit_AsyncFunctionDef(self, node: ast.AsyncFunctionDef):
        if not node.name.startswith("_"):
            docstring = ast.get_docstring(node, clean=False)
            if not docstring:
                segment = self._get_source_segment(node)
                if segment:
                    self.nodes_without_docstrings.append((node, segment))
        self.generic_visit(node)

    def visit_ClassDef(self, node: ast.ClassDef):
        if not node.name.startswith("_"):
            docstring = ast.get_docstring(node, clean=False)
            if not docstring:
                segment = self._get_source_segment(node)
                if segment:
                    self.nodes_without_docstrings.append((node, segment))
        self.generic_visit(node)


def generate_docstring_with_gemini(
    code_snippet: str,
    node_type: str,
    model: genai.GenerativeModel,
    max_retries: int = 3,
    retry_delay: int = 35,
) -> Optional[str]:
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –¥–æ–∫—Å—Ç—Ä–∏–Ω–≥ –¥–ª—è —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞ –∫–æ–¥–∞ —Å –ø–æ–º–æ—â—å—é Gemini.

    –ü—Ä–∏ –ø—Ä–µ–≤—ã—à–µ–Ω–∏–∏ –∫–≤–æ—Ç—ã API –¥–æ–±–∞–≤–ª—è–µ—Ç –∑–∞–¥–µ—Ä–∂–∫—É –∏ –ø–æ–≤—Ç–æ—Ä—è–µ—Ç –ø–æ–ø—ã—Ç–∫—É –¥–æ max_retries —Ä–∞–∑.

    Args:
        code_snippet: –§—Ä–∞–≥–º–µ–Ω—Ç –∫–æ–¥–∞ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–æ–∫—Å—Ç—Ä–∏–Ω–≥–∞
        node_type: –¢–∏–ø —É–∑–ª–∞ AST (Module, FunctionDef, ClassDef –∏ —Ç.–¥.)
        model: –≠–∫–∑–µ–º–ø–ª—è—Ä –º–æ–¥–µ–ª–∏ Gemini
        max_retries: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –ø–æ–ø—ã—Ç–æ–∫ –ø—Ä–∏ –æ—à–∏–±–∫–µ –∫–≤–æ—Ç—ã
        retry_delay: –í—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è –≤ —Å–µ–∫—É–Ω–¥–∞—Ö –º–µ–∂–¥—É –ø–æ–ø—ã—Ç–∫–∞–º–∏

    Returns:
        –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –¥–æ–∫—Å—Ç—Ä–∏–Ω–≥ –∏–ª–∏ None –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
    """
    prompt = f"""
    –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–ª–µ–¥—É—é—â–∏–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç –∫–æ–¥–∞ Python ({node_type}) –∏–∑ –ø—Ä–æ–µ–∫—Ç–∞ Django/DRF –∏ —Å–≥–µ–Ω–µ—Ä–∏—Ä—É–π –¥–ª—è –Ω–µ–≥–æ –ª–∞–∫–æ–Ω–∏—á–Ω—ã–π –∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–π –¥–æ–∫—Å—Ç—Ä–∏–Ω–≥ –≤ —Å—Ç–∏–ª–µ PEP 257 –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.
    –í–∫–ª—é—á–∏ –∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Ç–æ–≥–æ, —á—Ç–æ –¥–µ–ª–∞–µ—Ç –∫–æ–¥, –µ–≥–æ –∞—Ä–≥—É–º–µ–Ω—Ç—ã (–µ—Å–ª–∏ —ç—Ç–æ —Ñ—É–Ω–∫—Ü–∏—è/–º–µ—Ç–æ–¥) —Å –∏—Ö —Ç–∏–ø–∞–º–∏ (–µ—Å–ª–∏ –æ—á–µ–≤–∏–¥–Ω–æ) –∏ —á—Ç–æ –æ–Ω –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç (–µ—Å–ª–∏ –ø—Ä–∏–º–µ–Ω–∏–º–æ).
    –ù–µ –¥–æ–±–∞–≤–ª—è–π –Ω–∏–∫–∞–∫–æ–≥–æ –¥—Ä—É–≥–æ–≥–æ —Ç–µ–∫—Å—Ç–∞, –∫—Ä–æ–º–µ —Å–∞–º–æ–≥–æ –¥–æ–∫—Å—Ç—Ä–∏–Ω–≥–∞ –≤ —Ç—Ä–æ–π–Ω—ã—Ö –∫–∞–≤—ã—á–∫–∞—Ö (`\"\"\"Docstring goes here.\"\"\"`).
    –ù–µ –∏—Å–ø–æ–ª—å–∑—É–π markdown-–±–ª–æ–∫–∏ –∫–æ–¥–∞ (```python ... ```) –≤–æ–∫—Ä—É–≥ –¥–æ–∫—Å—Ç—Ä–∏–Ω–≥–∞.

    –§—Ä–∞–≥–º–µ–Ω—Ç –∫–æ–¥–∞:
    ```python
    {code_snippet}
    ```

    –°–≥–µ–Ω–µ—Ä–∏—Ä—É–π —Ç–æ–ª—å–∫–æ —Å–∞–º –¥–æ–∫—Å—Ç—Ä–∏–Ω–≥:
    """

    retry_count = 0
    while retry_count <= max_retries:
        try:
            generation_config = genai.types.GenerationConfig(
                temperature=0.4,
                # max_output_tokens=200
            )
            safety_settings = [
                {
                    "category": "HARM_CATEGORY_HARASSMENT",
                    "threshold": "BLOCK_MEDIUM_AND_ABOVE",
                },
                {
                    "category": "HARM_CATEGORY_HATE_SPEECH",
                    "threshold": "BLOCK_MEDIUM_AND_ABOVE",
                },
                {
                    "category": "HARM_CATEGORY_SEXUALLY_EXPLICIT",
                    "threshold": "BLOCK_MEDIUM_AND_ABOVE",
                },
                {
                    "category": "HARM_CATEGORY_DANGEROUS_CONTENT",
                    "threshold": "BLOCK_MEDIUM_AND_ABOVE",
                },
            ]

            response = model.generate_content(
                prompt,
                generation_config=generation_config,
                safety_settings=safety_settings,
            )

            if not response.parts:
                log.warning(
                    f"Gemini –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –¥–ª—è —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞:\n{code_snippet[:100]}..."
                )
                return None

            generated_text = response.text.strip()

            if generated_text.startswith('"""') and generated_text.endswith('"""'):
                docstring = generated_text[3:-3].strip()
                if docstring.startswith("```python"):
                    docstring = docstring[len("```python") :].strip()
                if docstring.endswith("```"):
                    docstring = docstring[: -len("```")].strip()
                return f'"""{docstring}"""'

            elif generated_text.startswith("'''") and generated_text.endswith("'''"):
                docstring = generated_text[3:-3].strip()
                if docstring.startswith("```python"):
                    docstring = docstring[len("```python") :].strip()
                if docstring.endswith("```"):
                    docstring = docstring[: -len("```")].strip()
                return f"'''{docstring}'''"

            else:
                log.warning(
                    f"Gemini –≤–µ—Ä–Ω—É–ª —Ç–µ–∫—Å—Ç –Ω–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ –¥–æ–∫—Å—Ç—Ä–∏–Ω–≥–∞:\n{generated_text}"
                )
                if len(generated_text.splitlines()) > 1:
                    return f'"""{generated_text}"""'
                return None

        except Exception as e:
            if "quota" in str(e).lower() and retry_count < max_retries:
                wait_time = retry_delay
                if "retry_delay" in str(e):
                    try:
                        import re

                        retry_info = re.search(
                            r"retry_delay\s*\{\s*seconds:\s*(\d+)", str(e)
                        )
                        if retry_info:
                            wait_time = int(retry_info.group(1)) + 3
                    except Exception:
                        pass

                retry_count += 1
                log.warning(
                    f"–ü—Ä–µ–≤—ã—à–µ–Ω–∞ –∫–≤–æ—Ç–∞ Gemini API. –û–∂–∏–¥–∞–Ω–∏–µ {wait_time} —Å–µ–∫ –ø–µ—Ä–µ–¥ –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –ø–æ–ø—ã—Ç–∫–æ–π ({retry_count}/{max_retries})..."
                )
                import time

                time.sleep(wait_time)
                continue
            else:
                log.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ Gemini API: {e}")
                if "API key not valid" in str(e):
                    console.print("[bold red]–û—à–∏–±–∫–∞: –ù–µ–≤–µ—Ä–Ω—ã–π API –∫–ª—é—á Gemini.[/]")
                elif "quota" in str(e).lower():
                    console.print(
                        "[bold yellow]–ü—Ä–µ–≤—ã—à–µ–Ω–∞ –∫–≤–æ—Ç–∞ Gemini API. –î–æ—Å—Ç–∏–≥–Ω—É—Ç –ª–∏–º–∏—Ç –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –ø–æ–ø—ã—Ç–æ–∫.[/]"
                    )
                return None

    return None


def add_docstrings_to_file(
    file_path: Path, changes: List[Tuple[ast.AST, str]], dry_run: bool
):
    """–î–æ–±–∞–≤–ª—è–µ—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–æ–∫—Å—Ç—Ä–∏–Ω–≥–∏ –≤ —Ñ–∞–π–ª."""
    if not changes:
        return

    if dry_run:
        console.print(
            f"[cyan]–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –º–µ—Å—Ç–∞ –¥–ª—è {len(changes)} –¥–æ–∫—Å—Ç—Ä–∏–Ω–≥–æ–≤ –≤:[/cyan] {file_path.relative_to(Path.cwd())}"
        )
        for node, docstring in changes:
            node_type = type(node).__name__
            name = getattr(node, "name", "module")

            if hasattr(node, "lineno"):
                console.print(f"  - {node_type} '{name}' (—Å—Ç—Ä–æ–∫–∞ {node.lineno})")
            else:
                console.print(f"  - {node_type} '{name}'")

            syntax = Syntax(docstring, "python", theme="default", line_numbers=False)
            console.print(syntax)
            console.print("-" * 20)
        return

    try:
        with open(file_path, "r", encoding="utf-8") as f:
            lines = f.readlines()

        changes.sort(key=lambda item: getattr(item[0], "lineno", 0), reverse=True)

        modified = False
        for node, docstring in changes:
            line_index = -1
            indentation = ""

            if isinstance(node, ast.Module):
                insert_pos = 0
                if lines:
                    if lines[0].startswith("#!"):
                        insert_pos = 1
                    if len(lines) > insert_pos and lines[insert_pos].strip().startswith(
                        "# -*- coding:"
                    ):
                        insert_pos += 1
                while insert_pos < len(lines) and not lines[insert_pos].strip():
                    lines.pop(insert_pos)

                docstring_lines = [line + "\n" for line in docstring.splitlines()]
                if docstring_lines:
                    lines[insert_pos:insert_pos] = docstring_lines + ["\n"]
                    modified = True

            elif isinstance(
                node, (ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef)
            ):
                line_index = node.lineno - 1
                if line_index < len(lines):
                    if node.body:
                        first_body_line_index = node.body[0].lineno - 1
                        if first_body_line_index < len(lines):
                            leading_whitespace = len(
                                lines[first_body_line_index]
                            ) - len(lines[first_body_line_index].lstrip(" "))
                            indentation = " " * leading_whitespace
                        else:
                            indentation = " " * (node.col_offset + 4)
                    else:
                        indentation = " " * (node.col_offset + 4)

                    docstring_lines = textwrap.indent(
                        docstring, indentation
                    ).splitlines()
                    docstring_lines = [line + "\n" for line in docstring_lines]

                    if docstring_lines:
                        lines[line_index + 1 : line_index + 1] = docstring_lines
                        modified = True
                else:
                    log.warning(
                        f"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –Ω–æ–º–µ—Ä —Å—Ç—Ä–æ–∫–∏ {node.lineno} –¥–ª—è —É–∑–ª–∞ –≤ {file_path}"
                    )

            else:
                log.warning(
                    f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ç–∏–ø —É–∑–ª–∞ –¥–ª—è –≤—Å—Ç–∞–≤–∫–∏ –¥–æ–∫—Å—Ç—Ä–∏–Ω–≥–∞: {type(node).__name__}"
                )

        if modified and not dry_run:
            console.print(
                f"[green]–û–±–Ω–æ–≤–ª–µ–Ω —Ñ–∞–π–ª:[/green] {file_path.relative_to(Path.cwd())}"
            )
            with open(file_path, "w", encoding="utf-8") as f:
                f.writelines(lines)

    except FileNotFoundError:
        console.print(
            f"[bold red]–û—à–∏–±–∫–∞: –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω –ø—Ä–∏ –ø–æ–ø—ã—Ç–∫–µ –∑–∞–ø–∏—Å–∏:[/bold red] {file_path}"
        )
    except Exception as e:
        console.print(
            f"[bold red]–û—à–∏–±–∫–∞ –ø—Ä–∏ –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ñ–∞–π–ª–∞ {file_path}:[/bold red] {e}"
        )
        log.exception(f"–ü–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–∏ –æ—à–∏–±–∫–∏ –¥–ª—è {file_path}:")


def main():
    parser = argparse.ArgumentParser(
        description="–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è Python docstrings –¥–ª—è Django/DRF –ø—Ä–æ–µ–∫—Ç–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Gemini.",
        formatter_class=argparse.RawDescriptionHelpFormatter,
    )
    parser.add_argument(
        "project_path", type=str, help="–ü—É—Ç—å –∫ –∫–æ—Ä–Ω–µ–≤–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ Django/DRF –ø—Ä–æ–µ–∫—Ç–∞."
    )
    parser.add_argument(
        "--api-key",
        type=str,
        default=os.environ.get(API_KEY_ENV_VAR),
        help=f"API –∫–ª—é—á Gemini. –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –æ–∫—Ä—É–∂–µ–Ω–∏—è {API_KEY_ENV_VAR}.",
    )
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="–í—ã–ø–æ–ª–Ω–∏—Ç—å –∞–Ω–∞–ª–∏–∑ –∏ –ø–æ–∫–∞–∑–∞—Ç—å, –∫–∞–∫–∏–µ –¥–æ–∫—Å—Ç—Ä–∏–Ω–≥–∏ –±—É–¥—É—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω—ã, –Ω–æ –Ω–µ –∏–∑–º–µ–Ω—è—Ç—å —Ñ–∞–π–ª—ã.",
    )
    parser.add_argument(
        "-v",
        "--verbose",
        action="store_true",
        help="–í–∫–ª—é—á–∏—Ç—å –ø–æ–¥—Ä–æ–±–Ω—ã–π –≤—ã–≤–æ–¥ (—É—Ä–æ–≤–µ–Ω—å DEBUG).",
    )
    parser.add_argument(
        "--max-retries",
        type=int,
        default=3,
        help="–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –ø–æ–ø—ã—Ç–æ–∫ –ø—Ä–∏ –ø—Ä–µ–≤—ã—à–µ–Ω–∏–∏ –∫–≤–æ—Ç—ã API (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 3).",
    )
    parser.add_argument(
        "--retry-delay",
        type=int,
        default=35,
        help="–í—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è –≤ —Å–µ–∫—É–Ω–¥–∞—Ö –º–µ–∂–¥—É –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 35).",
    )

    args = parser.parse_args()

    if args.verbose:
        log.setLevel(logging.DEBUG)

    if not args.api_key:
        console.print(f"[bold red]–û—à–∏–±–∫–∞: API –∫–ª—é—á Gemini –Ω–µ –Ω–∞–π–¥–µ–Ω.[/]")
        console.print(
            f"–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è {API_KEY_ENV_VAR} –∏–ª–∏ –ø–µ—Ä–µ–¥–∞–π—Ç–µ –∫–ª—é—á —á–µ—Ä–µ–∑ –∞—Ä–≥—É–º–µ–Ω—Ç --api-key."
        )
        sys.exit(1)

    project_path = Path(args.project_path).resolve()
    if not project_path.is_dir():
        console.print(
            f"[bold red]–û—à–∏–±–∫–∞: –£–∫–∞–∑–∞–Ω–Ω—ã–π –ø—É—Ç—å '{args.project_path}' –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–µ–π –∏–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç.[/]"
        )
        sys.exit(1)

    config = load_config(project_path)
    exclude_patterns = config.get("exclude", DEFAULT_EXCLUDE_PATTERNS)
    gemini_model_name = config.get("model_name", DEFAULT_GEMINI_MODEL)

    console.print(
        Panel(
            f"–ó–∞–ø—É—Å–∫ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ –¥–æ–∫—Å—Ç—Ä–∏–Ω–≥–æ–≤\n"
            f"–ü—Ä–æ–µ–∫—Ç: [cyan]{project_path}[/cyan]\n"
            f"–ú–æ–¥–µ–ª—å Gemini: [cyan]{gemini_model_name}[/cyan]\n"
            f"–ú–∞–∫—Å. –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –ø–æ–ø—ã—Ç–æ–∫: [cyan]{args.max_retries}[/cyan]\n"
            f"–ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –ø–æ–ø—ã—Ç–∫–∞–º–∏: [cyan]{args.retry_delay} —Å–µ–∫[/cyan]\n"
            f"–†–µ–∂–∏–º 'dry run': {'[bold green]–í–∫–ª—é—á–µ–Ω[/]' if args.dry_run else '[bold red]–í—ã–∫–ª—é—á–µ–Ω[/]'}",
            title="[bold blue]–ù–∞—Å—Ç—Ä–æ–π–∫–∏[/]",
            border_style="blue",
        )
    )

    console.print("\n[blue]–ü–æ–∏—Å–∫ Python —Ñ–∞–π–ª–æ–≤...[/]")
    py_files = find_python_files(project_path, exclude_patterns)

    if not py_files:
        console.print(
            "[yellow]–ù–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–∏ –æ–¥–Ω–æ–≥–æ Python —Ñ–∞–π–ª–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ (—Å —É—á–µ—Ç–æ–º –∏—Å–∫–ª—é—á–µ–Ω–∏–π).[/]"
        )
        sys.exit(0)

    console.print(f"–ù–∞–π–¥–µ–Ω–æ {len(py_files)} —Ñ–∞–π–ª–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞:")
    # for i, file in enumerate(py_files):
    #     console.print(f"  {i+1}. {file.relative_to(project_path)}")
    from rich.filesize import decimal
    from rich.markup import escape
    from rich.text import Text
    from rich.tree import Tree

    tree = Tree(
        f":open_file_folder: [link file://{project_path}]{escape(project_path.name)}",
        guide_style="bold bright_blue",
    )

    paths_dict = {}
    for file_path in py_files:
        parts = file_path.relative_to(project_path).parts
        current_level = paths_dict
        for i, part in enumerate(parts):
            if i == len(parts) - 1:
                current_level.setdefault("_files", []).append(file_path)
            else:
                current_level = current_level.setdefault(part, {})

    def build_tree(node, current_dict):
        dirs = sorted([d for d in current_dict if d != "_files"])
        files = sorted(current_dict.get("_files", []), key=lambda p: p.name)

        for d in dirs:
            branch = node.add(
                f":file_folder: [bold magenta]{escape(d)}[/]", guide_style="magenta"
            )
            build_tree(branch, current_dict[d])
        for f in files:
            text_filename = Text(f.name, "green")
            text_filename.highlight_regex(r"\.(py)$", "bold green")
            text_filename.stylize(f"link file://{f}")
            icon = "üêç "
            node.add(Text(icon) + text_filename)

    build_tree(tree, paths_dict)
    console.print(tree)
    console.print("-" * 60)

    try:
        genai.configure(api_key=args.api_key)
        model = genai.GenerativeModel(gemini_model_name)
        model.generate_content(
            "Test", generation_config=genai.types.GenerationConfig(max_output_tokens=5)
        )
    except Exception as e:
        console.print(
            f"[bold red]–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ Gemini ({gemini_model_name}): {e}[/]"
        )
        sys.exit(1)

    console.print(
        f"\n[blue]–ê–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–æ–≤ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–æ–∫—Å—Ç—Ä–∏–Ω–≥–æ–≤ ({'dry run' if args.dry_run else '–ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏–π'})...[/]"
    )

    files_processed = 0
    files_updated = 0
    docstrings_generated = 0

    with Progress(
        SpinnerColumn(),
        TextColumn("[progress.description]{task.description}"),
        BarColumn(),
        TextColumn("[progress.percentage]{task.percentage:>3.0f}%"),
        TimeElapsedColumn(),
        console=console,
        transient=False,
    ) as progress:
        task = progress.add_task("[green]–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–æ–≤...", total=len(py_files))

        for file_path in py_files:
            relative_file_path = file_path.relative_to(project_path)
            progress.update(task, description=f"[green]–§–∞–π–ª: {relative_file_path}")

            try:
                with open(file_path, "r", encoding="utf-8") as f:
                    source_code = f.read()
                tree = ast.parse(source_code, filename=str(file_path))

                finder = DocstringFinder(file_path)
                finder.visit(tree)

                nodes_to_document = finder.nodes_without_docstrings
                changes_for_file: List[Tuple[ast.AST, str]] = (
                    []
                )  # (node, generated_docstring)

                if nodes_to_document:
                    progress.update(
                        task,
                        description=f"[yellow]–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–ª—è: {relative_file_path} ({len(nodes_to_document)} —à—Ç.)",
                    )
                    for node, code_segment in nodes_to_document:
                        node_type = type(node).__name__
                        name = getattr(node, "name", "module")
                        log_line_info = (
                            f":{node.lineno}" if hasattr(node, "lineno") else ":module"
                        )
                        log.debug(
                            f"–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–æ–∫—Å—Ç—Ä–∏–Ω–≥–∞ –¥–ª—è {node_type} '{name}' –≤ {relative_file_path}{log_line_info}"
                        )

                        context_code = (
                            code_segment if code_segment else f"# {node_type}: {name}"
                        )
                        max_context_len = 2000
                        if len(context_code) > max_context_len:
                            context_code = (
                                context_code[:max_context_len] + "\n# ... (–∫–æ–¥ —É—Ä–µ–∑–∞–Ω)"
                            )
                            log.warning(
                                f"–ö–æ–¥ –¥–ª—è {node_type} '{name}' –≤ {relative_file_path} —É—Ä–µ–∑–∞–Ω –¥–æ {max_context_len} —Å–∏–º–≤–æ–ª–æ–≤."
                            )

                        generated_docstring = generate_docstring_with_gemini(
                            context_code,
                            node_type,
                            model,
                            max_retries=args.max_retries,
                            retry_delay=args.retry_delay,
                        )

                        if generated_docstring:
                            log.debug(
                                f"–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω –¥–æ–∫—Å—Ç—Ä–∏–Ω–≥ –¥–ª—è {node_type} '{name}':\n{generated_docstring}"
                            )
                            changes_for_file.append((node, generated_docstring))
                            docstrings_generated += 1
                        else:
                            log.warning(
                                f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –¥–æ–∫—Å—Ç—Ä–∏–Ω–≥ –¥–ª—è {node_type} '{name}' –≤ {relative_file_path}"
                            )
                            progress.update(
                                task,
                                description=f"[red]–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {relative_file_path}",
                            )

                    if changes_for_file:
                        add_docstrings_to_file(
                            file_path, changes_for_file, args.dry_run
                        )
                        if not args.dry_run:
                            files_updated += 1

                files_processed += 1

            except SyntaxError as e:
                console.print(
                    f"[bold red]–û—à–∏–±–∫–∞ —Å–∏–Ω—Ç–∞–∫—Å–∏—Å–∞ –≤ —Ñ–∞–π–ª–µ {relative_file_path}: {e}[/]"
                )
                progress.update(
                    task, description=f"[red]–û—à–∏–±–∫–∞ —Å–∏–Ω—Ç–∞–∫—Å–∏—Å–∞: {relative_file_path}"
                )
            except FileNotFoundError:
                console.print(
                    f"[bold red]–û—à–∏–±–∫–∞: –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏:[/bold red] {relative_file_path}"
                )
                progress.update(
                    task, description=f"[red]–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {relative_file_path}"
                )
            except Exception as e:
                console.print(
                    f"[bold red]–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞ {relative_file_path}: {e}[/]"
                )
                log.exception(f"–ü–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–∏ –æ—à–∏–±–∫–∏ –¥–ª—è {relative_file_path}:")
                progress.update(
                    task, description=f"[red]–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {relative_file_path}"
                )

            progress.advance(task)

    console.print("\n" + "=" * 60)
    console.print("[bold blue]–ó–∞–≤–µ—Ä—à–µ–Ω–æ.[/]")
    console.print(f"–í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ: {files_processed}")
    if args.dry_run:
        console.print(
            f"–ü–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ –±—É–¥–µ—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ –¥–æ–∫—Å—Ç—Ä–∏–Ω–≥–æ–≤: {docstrings_generated}"
        )
        console.print("[yellow]–†–µ–∂–∏–º 'dry run': –§–∞–π–ª—ã –Ω–µ –±—ã–ª–∏ –∏–∑–º–µ–Ω–µ–Ω—ã.[/]")
    else:
        console.print(
            f"–í—Å–µ–≥–æ –¥–æ–∫—Å—Ç—Ä–∏–Ω–≥–æ–≤ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ –∏ –¥–æ–±–∞–≤–ª–µ–Ω–æ: {docstrings_generated}"
        )
        console.print(f"–§–∞–π–ª–æ–≤ –æ–±–Ω–æ–≤–ª–µ–Ω–æ: {files_updated}")
    console.print("=" * 60)


if __name__ == "__main__":
    main()
